{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667494f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model.ipynb\n",
      "2.13.0\n",
      "importing Jupyter notebook from metrics.ipynb\n",
      "Train: 44 - 44 - 44\n",
      "Valid: 6 - 6 - 6\n",
      "Test: 5 - 5 - 5\n",
      "Training started...\n",
      "Epoch 1/20\n",
      "22/22 [==============================] - 711s 32s/step - loss: 0.6296 - dice_coef: 0.3704 - iou: 0.2282 - recall: 0.3165 - precision: 0.4754 - val_loss: 0.6939 - val_dice_coef: 0.3061 - val_iou: 0.1810 - val_recall: 0.1876 - val_precision: 0.4175 - lr: 1.0000e-05\n",
      "Epoch 2/20\n",
      "22/22 [==============================] - 714s 32s/step - loss: 0.5204 - dice_coef: 0.4796 - iou: 0.3164 - recall: 0.6102 - precision: 0.5425 - val_loss: 0.6956 - val_dice_coef: 0.3044 - val_iou: 0.1797 - val_recall: 0.0777 - val_precision: 0.2940 - lr: 1.0000e-05\n",
      "Epoch 3/20\n",
      "22/22 [==============================] - 745s 34s/step - loss: 0.4303 - dice_coef: 0.5697 - iou: 0.3997 - recall: 0.7518 - precision: 0.6089 - val_loss: 0.7001 - val_dice_coef: 0.2999 - val_iou: 0.1766 - val_recall: 0.0099 - val_precision: 0.0898 - lr: 1.0000e-05\n",
      "Epoch 4/20\n",
      "22/22 [==============================] - 661s 30s/step - loss: 0.3290 - dice_coef: 0.6710 - iou: 0.5061 - recall: 0.8430 - precision: 0.7616 - val_loss: 0.7089 - val_dice_coef: 0.2911 - val_iou: 0.1706 - val_recall: 8.6675e-06 - val_precision: 3.0877e-04 - lr: 1.0000e-05\n",
      "Epoch 5/20\n",
      "22/22 [==============================] - 664s 30s/step - loss: 0.2463 - dice_coef: 0.7537 - iou: 0.6057 - recall: 0.9004 - precision: 0.8802 - val_loss: 0.7204 - val_dice_coef: 0.2796 - val_iou: 0.1626 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 6/20\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1919 - dice_coef: 0.8081 - iou: 0.6787 - recall: 0.9301 - precision: 0.9131 \n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "22/22 [==============================] - 665s 30s/step - loss: 0.1919 - dice_coef: 0.8081 - iou: 0.6787 - recall: 0.9301 - precision: 0.9131 - val_loss: 0.7351 - val_dice_coef: 0.2649 - val_iou: 0.1528 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "22/22 [==============================] - 666s 30s/step - loss: 0.1711 - dice_coef: 0.8289 - iou: 0.7086 - recall: 0.9380 - precision: 0.9320 - val_loss: 0.7522 - val_dice_coef: 0.2478 - val_iou: 0.1417 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 8/20\n",
      "22/22 [==============================] - 652s 30s/step - loss: 0.1679 - dice_coef: 0.8321 - iou: 0.7131 - recall: 0.9396 - precision: 0.9304 - val_loss: 0.7678 - val_dice_coef: 0.2322 - val_iou: 0.1314 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 9/20\n",
      "22/22 [==============================] - 666s 30s/step - loss: 0.1644 - dice_coef: 0.8356 - iou: 0.7182 - recall: 0.9428 - precision: 0.9275 - val_loss: 0.7844 - val_dice_coef: 0.2156 - val_iou: 0.1209 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 10/20\n",
      "22/22 [==============================] - 664s 30s/step - loss: 0.1602 - dice_coef: 0.8398 - iou: 0.7244 - recall: 0.9448 - precision: 0.9330 - val_loss: 0.8001 - val_dice_coef: 0.1999 - val_iou: 0.1110 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 11/20\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.1603 - dice_coef: 0.8397 - iou: 0.7244 - recall: 0.9431 - precision: 0.9329 \n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "22/22 [==============================] - 707s 32s/step - loss: 0.1603 - dice_coef: 0.8397 - iou: 0.7244 - recall: 0.9431 - precision: 0.9329 - val_loss: 0.8153 - val_dice_coef: 0.1847 - val_iou: 0.1018 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-06\n",
      "Epoch 12/20\n",
      "22/22 [==============================] - 1861s 87s/step - loss: 0.1566 - dice_coef: 0.8434 - iou: 0.7296 - recall: 0.9447 - precision: 0.9380 - val_loss: 0.8294 - val_dice_coef: 0.1706 - val_iou: 0.0933 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 13/20\n",
      "22/22 [==============================] - 732s 33s/step - loss: 0.1563 - dice_coef: 0.8437 - iou: 0.7301 - recall: 0.9437 - precision: 0.9372 - val_loss: 0.8419 - val_dice_coef: 0.1581 - val_iou: 0.0859 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 14/20\n",
      "22/22 [==============================] - 738s 34s/step - loss: 0.1563 - dice_coef: 0.8437 - iou: 0.7306 - recall: 0.9464 - precision: 0.9332 - val_loss: 0.8519 - val_dice_coef: 0.1481 - val_iou: 0.0800 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 15/20\n",
      "22/22 [==============================] - 740s 34s/step - loss: 0.1574 - dice_coef: 0.8426 - iou: 0.7286 - recall: 0.9432 - precision: 0.9354 - val_loss: 0.8603 - val_dice_coef: 0.1397 - val_iou: 0.0751 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 16/20\n",
      "22/22 [==============================] - 735s 33s/step - loss: 0.1577 - dice_coef: 0.8423 - iou: 0.7284 - recall: 0.9451 - precision: 0.9346 - val_loss: 0.8676 - val_dice_coef: 0.1324 - val_iou: 0.0709 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 17/20\n",
      "22/22 [==============================] - 732s 33s/step - loss: 0.1552 - dice_coef: 0.8448 - iou: 0.7320 - recall: 0.9458 - precision: 0.9374 - val_loss: 0.8720 - val_dice_coef: 0.1280 - val_iou: 0.0684 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 18/20\n",
      "22/22 [==============================] - 1467s 68s/step - loss: 0.1569 - dice_coef: 0.8431 - iou: 0.7296 - recall: 0.9441 - precision: 0.9361 - val_loss: 0.8724 - val_dice_coef: 0.1276 - val_iou: 0.0682 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 1.0000e-07\n",
      "Epoch 19/20\n",
      "22/22 [==============================] - 781s 36s/step - loss: 0.1563 - dice_coef: 0.8437 - iou: 0.7304 - recall: 0.9436 - precision: 0.9360 - val_loss: 0.8661 - val_dice_coef: 0.1339 - val_iou: 0.0718 - val_recall: 0.0026 - val_precision: 0.3570 - lr: 1.0000e-07\n",
      "Epoch 20/20\n",
      "22/22 [==============================] - 726s 33s/step - loss: 0.1542 - dice_coef: 0.8458 - iou: 0.7332 - recall: 0.9454 - precision: 0.9366 - val_loss: 0.8420 - val_dice_coef: 0.1580 - val_iou: 0.0859 - val_recall: 0.0188 - val_precision: 0.7622 - lr: 1.0000e-07\n",
      "Training completed.\n",
      "INFO:tensorflow:Assets written to: files2\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: files2\\model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Shape: (512, 512, 3)\n",
      "Sample Mask Shape: (512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from model import build_unet\n",
    "from metrics import dice_loss, dice_coef, iou\n",
    "\n",
    "# Rest of the code...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    \"\"\" Create a directory if it doesn't exist. \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.1):\n",
    "    images = sorted(glob(os.path.join(path, \"CXR_png\", \"*.png\")))\n",
    "    masks1 = sorted(glob(os.path.join(path, \"GTMask\", \"leftMask\", \"*.png\")))\n",
    "    masks2 = sorted(glob(os.path.join(path, \"GTMask\", \"rightMask\", \"*.png\")))\n",
    "\n",
    "    train_x, valid_x, train_y1, valid_y1, train_y2, valid_y2 = train_test_split(\n",
    "        images, masks1, masks2, test_size=split, random_state=42\n",
    "    )\n",
    "\n",
    "    train_x, test_x, train_y1, test_y1, train_y2, test_y2 = train_test_split(\n",
    "        train_x, train_y1, train_y2, test_size=split, random_state=42\n",
    "    )\n",
    "\n",
    "    return (train_x, train_y1, train_y2), (valid_x, valid_y1, valid_y2), (test_x, test_y1, test_y2)\n",
    "\n",
    "\n",
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x.astype(np.float32) / 255.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def read_mask(path1, path2):\n",
    "    x1 = cv2.imread(path1, cv2.IMREAD_GRAYSCALE)\n",
    "    x2 = cv2.imread(path2, cv2.IMREAD_GRAYSCALE)\n",
    "    x = x1 + x2\n",
    "    x = cv2.resize(x, (W, H))\n",
    "    x = x.astype(np.float32) / np.max(x)\n",
    "    x = x > 0.5\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x\n",
    "\n",
    "\n",
    "def tf_parse(x, y1, y2):\n",
    "    def _parse(x, y1, y2):\n",
    "        x = x.decode()\n",
    "        y1 = y1.decode()\n",
    "        y2 = y2.decode()\n",
    "\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y1, y2)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y1, y2], [tf.float32, tf.float32])\n",
    "    x.set_shape([H, W, 3])\n",
    "    y.set_shape([H, W, 1])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def tf_dataset(X, Y1, Y2, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y1, Y2))\n",
    "    dataset = dataset.shuffle(buffer_size=200)\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Global parameters \"\"\"\n",
    "    H = 512\n",
    "    W = 512\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    batch_size = 2\n",
    "    lr = 1e-5\n",
    "    num_epochs = 20\n",
    "    model_path = os.path.join(\"files2\", \"model\")\n",
    "    csv_path = os.path.join(\"files2\", \"data.csv\")\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"C:\\\\Users\\\\IIITSKLM\\\\Desktop\\\\indiana\"\n",
    "\n",
    "    (train_x, train_y1, train_y2), (valid_x, valid_y1, valid_y2), (test_x, test_y1, test_y2) = load_data(dataset_path)\n",
    "    print(f\"Train: {len(train_x)} - {len(train_y1)} - {len(train_y2)}\")\n",
    "    print(f\"Valid: {len(valid_x)} - {len(valid_y1)} - {len(valid_y2)}\")\n",
    "    print(f\"Test: {len(test_x)} - {len(test_y1)} - {len(test_y2)}\")\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y1, train_y2, batch=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y1, valid_y2, batch=batch_size)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = build_unet((H, W, 3))\n",
    "    metrics = [dice_coef, iou, Recall(), Precision()]\n",
    "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=metrics)\n",
    "\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path)\n",
    "    ]\n",
    "\n",
    "    print(\"Training started...\")\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=valid_dataset,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "    \"\"\" Save the model \"\"\"\n",
    "    model.save(model_path, save_format='tf')\n",
    "\n",
    "    \"\"\" Inspect the data \"\"\"\n",
    "    sample_idx = 0  # Index of the sample to visualize\n",
    "    sample_image = read_image(train_x[sample_idx])\n",
    "    sample_mask = read_mask(train_y1[sample_idx], train_y2[sample_idx])\n",
    "\n",
    "    # Print the shapes of the sample image and mask\n",
    "    print(\"Sample Image Shape:\", sample_image.shape)\n",
    "    print(\"Sample Mask Shape:\", sample_mask.shape)\n",
    "\n",
    "    # Visualize the sample image and mask\n",
    "    cv2.imshow(\"Sample Image\", sample_image)\n",
    "    cv2.imshow(\"Sample Mask\", sample_mask)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36583002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09600b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
